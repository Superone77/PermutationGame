#!/usr/bin/env python3
"""
Simple test for q_proj and k_proj quadruple reordering
"""

import torch
import numpy as np
from reorder_algorithms import qk_proj_quadruple_reorder_index, compute_reorders

def test_qk_quadruple():
    """Test the quadruple reordering for q_proj and k_proj"""
    print("Testing q_proj and k_proj quadruple reordering...")
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    D = 128
    block_size = 16
    K = D // block_size
    
    # ç”Ÿæˆ q_proj å’Œ k_proj çš„ç»Ÿè®¡ä¿¡æ¯
    q_xmax = torch.randn(D) * 2.0
    q_xmin = torch.randn(D) * 1.5
    k_xmax = torch.randn(D) * 1.8
    k_xmin = torch.randn(D) * 1.2
    
    print(f"Data shape: {D}, Block size: {block_size}, Number of blocks: {K}")
    
    # æµ‹è¯•å››å…ƒæ•°é‡æ’åº
    idx, counts = qk_proj_quadruple_reorder_index(q_xmax, q_xmin, k_xmax, k_xmin, block_size, top_pct=0.1)
    
    print(f"Generated index shape: {idx.shape}")
    print(f"Generated counts: {counts}")
    print(f"Index range: [{idx.min()}, {idx.max()}]")
    print(f"Unique indices: {len(torch.unique(idx))}")
    
    # éªŒè¯ç´¢å¼•çš„å®Œæ•´æ€§
    assert len(idx) == D, f"Index length {len(idx)} != data length {D}"
    assert len(torch.unique(idx)) == D, "Index contains duplicates"
    assert idx.min() == 0 and idx.max() == D-1, "Index range incorrect"
    
    print("âœ“ Quadruple reordering test passed!")

def test_compute_reorders_with_qk():
    """Test compute_reorders with q_proj and k_proj"""
    print("\nTesting compute_reorders with q_proj and k_proj...")
    
    # åˆ›å»ºæ¨¡æ‹Ÿçš„ oc_stats
    D = 64
    block_size = 16
    
    oc_stats = {
        'layer_0_self_attn.q_proj': (torch.randn(D) * 2.0, torch.randn(D) * 1.5),
        'layer_0_self_attn.k_proj': (torch.randn(D) * 1.8, torch.randn(D) * 1.2),
        'layer_0_self_attn.v_proj': (torch.randn(D) * 1.6, torch.randn(D) * 1.0),
        'layer_0_self_attn.o_proj': (torch.randn(D) * 1.4, torch.randn(D) * 0.8),
    }
    
    # æµ‹è¯• hybrid_plus æ–¹æ³•
    print("Testing hybrid_plus method...")
    perms = compute_reorders(oc_stats, block_size=block_size, method='hybrid_plus', hybrid_top_pct=0.1)
    
    print(f"Generated permutations for modules: {list(perms.keys())}")
    
    # æ£€æŸ¥ q_proj å’Œ k_proj æ˜¯å¦æœ‰ç›¸åŒçš„é‡æ’åºé¡ºåº
    if 'layer_0_self_attn.q_proj' in perms and 'layer_0_self_attn.k_proj' in perms:
        q_perm = perms['layer_0_self_attn.q_proj']
        k_perm = perms['layer_0_self_attn.k_proj']
        
        if torch.equal(q_perm, k_perm):
            print("âœ“ q_proj and k_proj have identical reordering (quadruple method used)")
        else:
            print("âœ— q_proj and k_proj have different reordering")
    else:
        print("âœ— q_proj or k_proj not found in permutations")
    
    # éªŒè¯æ‰€æœ‰æ’åˆ—çš„æœ‰æ•ˆæ€§
    for name, perm in perms.items():
        assert len(perm) == D, f"Permutation length mismatch for {name}"
        assert len(torch.unique(perm)) == D, f"Permutation contains duplicates for {name}"
        assert perm.min() == 0 and perm.max() == D-1, f"Permutation range incorrect for {name}"

if __name__ == '__main__':
    test_qk_quadruple()
    test_compute_reorders_with_qk()
    print("\nğŸ‰ All tests passed!")
